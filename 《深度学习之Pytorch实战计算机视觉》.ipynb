{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 以下内容来自<<深度学习之PyTorch实战计算机视觉>>\n唐进民 著","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n#torch.FloatTensor用于生成数据类型为浮点型的Tensor，传递给torch.FloatTensor的参数可以是一个列表也可以是一个维度值。\na = torch.FloatTensor([1.1,2.1,3.1,4.1,5.1])\nb = torch.IntTensor([1,2,3,4,5])\nc = torch.rand(2,3)\nd = torch.randn(2,3) #符合正态分布\n#e = torch.range(start,end,step)\n#torch.zeros()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch的运算\na_abs = torch.abs(a)\nc_plus_d   = torch.add(c,d)\n#如果小于下边界重写成下边界，上边界亦是如此\nb_clamp = torch.clamp(b,-1,3)\nc_div_d = torch.div(c,d) #除法\nc_mul_d = torch.mul(c,d) #逐项乘法\na_squared = torch.pow(a,2)\nf = torch.rand(3,2)\nd_mm_f = torch.mm(d,f) #矩阵乘法","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#先通过输入的Tensor数据类型的变量在神经网络的前向传播过程中生成一张计算图，然后根据这个计算图和输出结果准确计算出每个参数需要更新的梯度，并反向传播完成梯度更新。\n#在实践中需要用到Variable类对我们定义的Tensor数据类型进行封装，在封装后，计算图的每个节点就是一个Variable对象。\n#如果用X表示结点，X.Tensor表示变量，X.grad表示梯度\n#==============================================================================================\n#                          采用自动梯度的方法自定义简单的二层网络\n#==============================================================================================\n\nfrom torch.autograd import Variable\nbatch_n = 100 #在一个批次中输入数据的数量\nhidden_layer = 100 \ninput_data = 1000\noutput_data = 10\n\nepoch_n = 20\nlearning_rate = 1e-6\nfor epoch in range(epoch_n):\n    y_pred = x.mm(w1).clamp(min=0).mm(w2) #用了一层RELU这是？ 一层FCN，一层RELU，一层FCN，NB！\n    loss = (y_pred - y).pow(2).sum()\n    print('epoch:{},loss:{:.4f}'.format(epoch,loss.data[0]))\n    \n    loss.backward()\n    \n    w1.data = learning_rate * w1.grad.data\n    w2.data = learning_rate * w2.grad.data\n    \n    w1.grad.data.zero_()\n    w2.grad.data.zero_()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#==============================================================================================\n#                       通过构建一个继承了torch.nn.Module的新类实现前向传播和后向传播\n#==============================================================================================\n\n#报错提醒，对于高版本的pytorch，不能使用loss.data[0],而应该实用loss.item()取而代之\n\n\nimport torch\nfrom torch.autograd import Variable\nbatch_n = 64 #在一个批次中输入数据的数量\nhidden_layer = 100 \ninput_data = 1000\noutput_data = 10\n\nclass Model(torch.nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n    def forward(self,input,w1,w2):\n        x = torch.mm(input,w1)\n        x = torch.clamp(x,min=0)\n        x = torch.mm(x,w2)\n        return x\n    def backward(self):\n        pass\n    #后向传播如果没有特别的需求，则在一般情况下不进行调整。\nmodel = Model()\n\n#准备好数据集开始训练啦！\nx = Variable(torch.randn(batch_n,input_data),requires_grad=False)\ny = Variable(torch.randn(batch_n,output_data),requires_grad=False)\n\nw1 = Variable(torch.randn(input_data,hidden_layer),requires_grad = True)\nw2 = Variable(torch.randn(hidden_layer,output_data),requires_grad = True)\n\nepoch_n = 30\nlearning_rate = 1e-6\n\nfor epoch in range(epoch_n):\n    y_pred = model(x,w1,w2)\n    loss = (y_pred - y).pow(2).sum()\n    print('epoch:{},loss:{:.4f}'.format(epoch,loss.item()))\n    loss.backward()\n    \n    w1.data -= learning_rate * w1.grad.data\n    w2.data -= learning_rate * w2.grad.data\n    \n    w1.grad.data.zero_()\n    w2.grad.data.zero_()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.nn包里面有很多帮助快速搭建网络的工具：比如CNN的卷积层，池化层，全连接层，防止过拟合参数的归一化方法，Dropout方法\n#激活函数部分的线性激活函数，非线性激活函数的相关方法.\nimport torch\nfrom torch.autograd import Variable\nbatch_n = 64 #在一个批次中输入数据的数量\nhidden_layer = 100 \ninput_data = 1000\noutput_data = 10\nx = Variable(torch.randn(batch_n,input_data),requires_grad=False)\ny = Variable(torch.randn(batch_n,output_data),requires_grad=False)\n\n#torch.nn.Sequential是torch.nn的一种序列容器，通过在容器中嵌套各种实现神经网络中具体功能相关的类，完成网络的搭建\n#最主要的是，参数会按照我们定义好的序列自动传递下去。！！！容器中模块的加入有两种方式，其一：直接嵌套。其二：以为orderdict有序字典的方式传入\n#后者搭建的模型每个模块都有我们给它起的名字，而前者默认使用从零开始的数字序列作为每个模块的名字。\n\n#TYPR1:直接嵌套\nmodels_TYPE1 = torch.nn.Sequential(\n   torch.nn.Linear(input_data,hidden_layer),\n   torch.nn.ReLU(),\n   torch.nn.Linear(hidden_layer,output_data)\n)\nprint(models_TYPE1)\n\n#TYPE2:使用orderdict有序字典进行传入\nfrom collections import OrderedDict\nmodels_TYPE2 = torch.nn.Sequential(\n    OrderedDict([\n        ('Line1',torch.nn.Linear(input_data,hidden_layer)),\n        ('Relu1',torch.nn.ReLU()),\n        ('Line2',torch.nn.Linear(hidden_layer,output_data))\n                ])\n                                  )\nprint(models_TYPE2)\n\n#使用orderdict的方法可以让我们更便捷的找到模型中相应的模块并进行操作。\n#torch.nn.Linear(inputsize,outputsize,use_bias?) 在定义这一层时，函数内部已经完成了对于这一层参数的初始化\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#激活函数介绍: torch.nn.ReLU\n#            torch.nn.Tanh\n#            torch.nn.LeakyReLU\n#            torch.nn.Sigmoid\n#            torch.nn.Softmax\n\nimport torch\nfrom torch.autograd import Variable\nloss_f = torch.nn.MSELoss()  #MSELoss常常用于回归问题\n#损失函数介绍\n#            torch.nn.L1Loss  两个输入维度一致\n#            torch.nn.CrossEntropyLoss 常常用于分类问题，第一个参数的维度是(a,b) 另一个是(a)\n#            CrossEntropyLoss函数是把结果先进性softmax归一化然后再放到传统的softmax里面\n#            两个参数分别是：a个样本对于b种label的值、a个样本实际的label\n#            torch.nn.LeakyReLU\n\n\n\n#随机生成了两个Tensor，然后求取MSE\nx = Variable(torch.randn(100,100))\ny = Variable(torch.randn(100,100))\nloss = loss_f(x,y)\n#print(loss.data)\n\n#随机生成了两个Tensor，然后求取CrossEntropyLoss.\n#注意，第二个参数一定得是torch.LongTensor!!!!!!\n\nloss_f = torch.nn.CrossEntropyLoss()\nx = Variable(torch.randn(5,3)) #5个样本，2种类label。\ny = Variable(torch.LongTensor([1,0,1,0,1]))\nloss = loss_f(x,y)\n\nepoch_n = 10000\ninput_data = 1000\noutput_data = 10\n#print(loss.data)\n\nx = Variable(torch.randn(batch_n,input_data),requires_grad=False)\ny = Variable(torch.randn(batch_n,output_data),requires_grad=False)\nloss_fn = torch.nn.MSELoss()\nfor epoch in range(epoch_n):\n    y_pred = models_TYPE2(x)\n    loss = loss_fn(y_pred,y)\n    if epoch % 1000 == 0:\n        print('epoch:{},loss:{}'.format(epoch,loss.item()))\n    models_TYPE2.zero_grad()\n    loss.backward()\n    for param in models_TYPE2.parameters():\n        param.data -= param.grad.data * learning_rate\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#使用高级的优化器，而不是简单的全局梯度下降\n#在torch.optim包里提供了非常多的可实现参数自动化的类，比如:SGD,AdaGrad,RMSProp,Adam等\n#=============================================================================\n#                       完整的基于torch的神经网络\n#=============================================================================\n\n#神文：https://blog.csdn.net/sinat_16643223/article/details/86670137\n#只有使用SGD才考虑batch,用于SGD的一批数据量就是1个batch_n, set_size = batch_n * batch_size\n#                                                     batch_size = 1时，就是纯正的梯度下降，当你的GPU足够牛批时，batch_size越小越好.\n#一个batch size地样本走一遍后，每个样本都会算出一个损失函数值，把这些损失函数值相加再处以batch size值可以得出这一个batch地平均损失函数值，最后是拿这个平均损失函数值去梯度下降更新参数值。\n#epoch=n  代表把整个训练集训练n遍。\n\nimport torch\nfrom torch.autograd import Variable\n\nbatch_n = 100\ninput_data = 1000\nhidden_layer = 1000\noutput_data = 10\n\nx = Variable(torch.randn(batch_n,input_data),requires_grad = False)\ny = Variable(torch.randn(batch_n,output_data),requires_grad = False)\n\nmodels = torch.nn.Sequential(\n         torch.nn.Linear(input_data,hidden_layer),\n         torch.nn.ReLU(),\n         torch.nn.Linear(hidden_layer,output_data)\n)\n\nepoch_n = 10000\nlearning_rate = 1e-4\nloss_f = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(models.parameters(),lr=learning_rate) #第一个参量是被优化的参数，第二个参量是学习率的初始值\n\n#开始训练\nfor epoch in range(epoch_n):\n    y_pred = models(x)\n    loss = loss_f(y_pred,y)\n    if epoch % 100 == 0:\n        print('epoch:{},loss:{}'.format(epoch,loss.item()))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#实战MNIST\n#具体过程：模型训练 -> 模型测试\n#torch.nn实现网络结构,激活函数，损失函数。torch.optim是优化器，torch.autograd实现自动有梯度下降\n\n#torchvision包的主要功能是实现数据的导入，预处理，预览等。\n\nimport torch\nimport torchvision\nfrom torchvision import datasets,transforms #datasets用于下载数据集，transforms提供了丰富的类对载入的数据进行变换，下载让我们看看如何变幻\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\n#常用的数据包COCO,ImageNet,CIFAR都可以通过这个函数下载\n\ntransform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.5],std=[0.5])])\n\n#tips:一定要注意transformer的维度问题！！！不然会报出[1,28,28] cannot broadcast to [3,28,28]\n#对于MNIST可以不用数据增强，因为对模型训练来说已经足够了\n#我们可以把transforms.Compose看作是和torch.nn.Sequential一样的容器,可以装很多数据预处理模块,传入的参量是一个列表。\n#对于torchvison常用的数据变换操作的介绍我放在Picture_process模块中介绍。\n\ndata_train = datasets.MNIST(root='./',transform=transform,train=True,download=True)\ndata_test = datasets.MNIST(root='./',transform=transform,train=False,download=True)\n\nbatch_size = 64\n\ndata_loader_train = torch.utils.data.DataLoader(dataset=data_train,batch_size=batch_size,shuffle=True)\ndata_loader_test = torch.utils.data.DataLoader(dataset=data_test,batch_size=batch_size,shuffle=True)\n#data_loader_train是一个可迭代对象，直接拿next(iter())取走即可\n#torchvision.utils.make_grid的参数就是一个批次的装载数据\n\nimages,labels = next(iter(data_loader_train)) #data_loader这个可迭代对象是一个四维的东西。\nprint(images.shape)\nimg = torchvision.utils.make_grid(images)\n#torchvision.utils.make_grid 最多传入四个参数，batch_size,channel,height,weight\n\nimg = img.numpy().transpose(1,2,0)\nstd = [0.5,0.5,0.5]\nmean = [0.5,0.5,0.5]\nimg = img*std + mean\nprint([labels[i] for i in range(64)])\nplt.imshow(img)\n#用plt打印需要注意必须必须必须传入(height,weight,channel)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(torch.nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n        self.conv1 = torch.nn.Sequential(\n                     torch.nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1),\n                     torch.nn.ReLU(),\n                     torch.nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n                     torch.nn.ReLU(),\n                     torch.nn.MaxPool2d(stride=2,kernel_size=2)  )#池化层第一个参数是步长，第二个参数位置是池化核大小\n        \n        self.dense = torch.nn.Sequential(\n                     torch.nn.Linear(128*14*14,1024),\n                     torch.nn.ReLU(),\n                     #dropout每epoch时选择丢弃的神经连接是不同的，这样做是为了让我们最后训练出的模型对于各部分的参数不产生过度依赖\n                     torch.nn.Dropout(p=0.5),#dropout默认0.5\n                     torch.nn.Linear(1024,10)                               )\n        \n    def forward(self,x):\n        x = self.conv1(x)\n        x = x.view(-1,128*14*14) #扁平化，从conv1层输出的的是14*14的128通道的feature_map\n        x = self.dense(x)\n        return x\n    \nmodel = Model()\nprint('========================================================================================')\nprint(model)\nprint('========================================================================================')\n\nloss_f = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())     \n\nn_epochs = 15\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    loss_f = loss_f.cuda()\n\nfor epoch in range(n_epochs):\n    running_loss = 0.0\n    running_correct = 0\n    for data in data_loader_train:\n        x_train,y_train = data\n        x_train,y_train = Variable(x_train),Variable(y_train)\n        x_train = x_train.cuda()\n        y_train = y_train.cuda()\n        outputs = model(x_train)\n        _,pred = torch.max(outputs.data,1)\n        optimizer.zero_grad()\n        loss = loss_f(outputs,y_train)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        running_correct += torch.sum(pred==y_train.data)\n    print('epoch is:{},loss is:{}'.format(epoch,loss))\n\n    #测试啦!!!\n    testing_correct = 0\n    for data in data_loader_test:\n        x_test,y_test = data\n        x_test,y_test = Variable(x_test),Variable(y_test)\n        x_test = x_test.cuda()\n        y_test = y_test.cuda()\n        outputs = model(x_test)\n        _,pred = torch.max(outputs.data,1)\n        testing_correct += torch.sum(pred == y_test.data)\n    print(\"CORRECT IS:{}\".format(testing_correct/len(data_test)))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),'./')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#summary(model,(3,32,32))非常牛批直接查看网络结构\n#pip install torchsummary\n\n#随便找几个图儿意思意思\nimport matplotlib.pyplot as plt \ndata_loader_test = torch.utils.data.DataLoader(dataset=data_test,batch_size=4,shuffle=True)\nx_test,y_test = next(iter(data_loader_test))\ninputs = Variable(x_test)\ninputs = inputs.cuda()\npred = model(inputs)\n_,pred = torch.max(pred,1)\n\nprint('predict label is:',[i for i in pred.data])\nprint('real label is:',[i for i in y_test])\n\nimg = torchvision.utils.make_grid(x_test)\nimg = img.numpy().transpose(1,2,0)\nstd = [0.5,0.5,0.5]\nmean = [0.5,0.5,0.5]\nimg = img*std + mean\nplt.imshow(img)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model = Model()   \nmodel = model.cuda()    \nsummary(model,(3,32,32))   \n!!!直接查看各层featuremap大小","metadata":{}},{"cell_type":"code","source":"#tensor转list\nimport torch\nimport numpy as np\n\na = torch.FloatTensor([1.0,2.0,3.0,4.0,5.0])\na = a.cuda()\na = np.array(a.cpu())\na = a.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 迁移学习（猫狗大战）","metadata":{}},{"cell_type":"code","source":"#对于原始数据比较少的问题，我们可以使用迁移学习进行有效的解决。\n#我们通过对一个训练好的模型进行细微调整，就能将其应用到相似的问题中。\nimport torch\nimport torchvision\nfrom torchvision import datasets,transforms\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n\n#数据预处理\n#torchvision.ImageFolder是一个通用的数据集加载器，他要求我们以data/train/cat这种方式来存放图片，label会顺序返回的\n#我们得到的dataset,它的结构就是[(img_data,class_id),(img_data,class_id),…] \n#注意torchvision.datasets.ImageFolder的使用格式鸭\n\n\ndata_dir = '../input/dogs-vs-cats/dataset'\ndata_transform = {x:transforms.Compose([transforms.Scale([64,64]),transforms.ToTensor()]) for x in ['training_set','test_set']}\nimage_datasets = {x:datasets.ImageFolder(root = os.path.join(data_dir,x),transform = data_transform[x]) for x in ['training_set','test_set']}\ndataloader = {x:torch.utils.data.DataLoader(dataset = image_datasets[x],batch_size=16,shuffle=True) for x in ['training_set','test_set']}\n#拼接文件名：   os.path.join\n#目录下的文件名 os.path.dirname\n#文件是否存在   os.path.exists\n#是否是目录名   os.path.isdir\n#是否是文件名   os.path.isfil\nx_example,y_example = next(iter(dataloader['training_set']))\n\n#展示标签及对应的label\n#index_classes = image_datasets['training_set'].class_to_idx\n#print(index_classes)\n\nimg = torchvision.utils.make_grid(x_example)\nimg = img.numpy().transpose([1,2,0])\n#print([example_classes[i] for i in y_example])\nplt.imshow(img)\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**本节会先搭建一个简化的VGGNet，然后迁移一个完整的VGG16框架，最后迁移一个ResNet50架构**","metadata":{}},{"cell_type":"code","source":"import torch\n#这个网络是把paper中的VGGNet\n#VGGNet删除了最后3个卷积层和1个池化层\nclass VGGNet(torch.nn.Module):\n    def __init__(self):\n        super(VGGNet,self).__init__()\n        self.Conv = torch.nn.Sequential(\n           torch.nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.MaxPool2d(kernel_size=2,stride=2),\n            \n           torch.nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.MaxPool2d(kernel_size=2,stride=2),\n            \n           torch.nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.MaxPool2d(kernel_size=2,stride=2),\n            \n           torch.nn.Conv2d(256,512,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1),\n           torch.nn.ReLU(),\n           torch.nn.MaxPool2d(kernel_size=2,stride=2)    \n        )\n        \n        self.Classes = torch.nn.Sequential(\n           torch.nn.Linear(4*4*512,1024),\n           torch.nn.ReLU(),\n           torch.nn.Dropout(p=0.5),\n           torch.nn.Linear(1024,2)\n        )\n    def forward(self,x):\n        x = self.Conv(x)\n        x = x.view(-1,4*4*512)\n        x = self.Classes(x)\n        return x\n\nvggnet = VGGNet()\nprint('======================================================================================')\nprint(vggnet)\nprint('======================================================================================')\n\n#定义损失函数和优化器\nloss_f = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vggnet.parameters(),lr=1e-5)\n\nepoch_n = 30\n\nif torch.cuda.is_available(): \n    vggnet = vggnet.cuda() \n    loss_f = loss_f.cuda()\n    \nfor epoch in range(epoch_n):\n    print('Epoch {}/{}'.format(epoch,epoch_n-1))\n    print('-'*20)\n    for phase in ['training_set','test_set']:\n        if phase == 'training_set':\n            print('Training...')\n            vggnet.train(True)\n        else:\n            print('Validing...')\n            vggnet.train(False)\n        running_loss = 0.0\n        running_corrects= 0\n    \n        for batch,data in enumerate(dataloader[phase],1):\n            x,y = data\n            x,y = x.cuda(),y.cuda()\n            y_pred = vggnet(x)\n            _,pred = torch.max(y_pred.data,1)\n            optimizer.zero_grad()\n            loss = loss_f(y_pred,y)\n        \n            if phase == 'training_set':\n               loss.backward()\n               optimizer.step()\n            running_loss += loss.item()\n            running_corrects += torch.sum(pred == y.data)\n        \n            if batch%100 == 0 and phase =='training_set':\n                print('Batch:{},Train Loss:{:.4f},Train ACC:{:.4f}'.format(batch,running_loss/batch,100*running_corrects/(16*batch)))\n    \n        epoch_loss = running_loss*16/len(image_datasets[phase])\n        epoch_acc = 100 * running_corrects/len(image_datasets[phase])\n        print('{} Loss:{:.4f} Acc:{:.4f}%'.format(phase,epoch_loss,epoch_acc))\n    \n      \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 迁移学习VGG16   (VGG大概比Alexnet慢5~6倍)","metadata":{}},{"cell_type":"code","source":"#首先需要下载已经具备最优参数的模型，这需要对于之前的 vggnet = VGGNet() 进行替换，因为我们不再需要自己搭建和定义模型了，而是通过代码自动下载模型并直接调用。\nfrom torchvision import models\nvggnet_transfer = models.vgg16(pretrained=True)\n#print('==================================================================')\n#print(vggnet_transfer)#我们发现这个下载好的网络的输出参数是1000\n#print('==================================================================')\n#调整下载的模型，其基本思想是冻结卷积神经网络中全连接层之前的全部网络层次，让这些被冻结的网络层次中的参数在模型的训练过程中不进行参数的梯度更新\n#能够被优化的参数仅仅是没有被冻结的全连接层的全部参数\n\n#冻结操作\nfor param in vggnet_transfer.parameters():\n    param.requires_grad = False\n\nvggnet_transfer.classifier = torch.nn.Sequential(\n                            torch.nn.Linear(25088,4096),\n                            torch.nn.ReLU(),\n                            torch.nn.Dropout(p=0.5),\n                            torch.nn.Linear(4096,4096),\n                            torch.nn.ReLU(),\n                            torch.nn.Dropout(p=0.5),\n                            torch.nn.Linear(4096,2)\n)\n\n\ncost = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vggnet_transfer.classifier.parameters(),lr=1e-5)\n\nif torch.cuda.is_available(): \n    vggnet_transfer = vggnet_transfer.cuda() \n    cost = cost.cuda()\n    \nprint('==================================================================')\nprint(vggnet_transfer)#修改了FCN之后的vggnet_transfer\nprint('==================================================================')\n\nepoch_n = 10\n\nfor epoch in range(epoch_n):\n    print('Epoch {}/{}'.format(epoch,epoch_n-1))\n    print('-'*20)\n    for phase in ['training_set','test_set']:\n        if phase == 'training_set':\n            print('Training...')\n            vggnet.train(True)\n        else:\n            print('Validing...')\n            vggnet.train(False)\n        running_loss = 0.0\n        running_corrects= 0\n    \n        for batch,data in enumerate(dataloader[phase],1):\n            x,y = data\n            x,y = x.cuda(),y.cuda()\n            y_pred = vggnet_transfer(x)\n            _,pred = torch.max(y_pred.data,1)\n            optimizer.zero_grad()\n            loss = cost(y_pred,y)\n        \n            if phase == 'training_set':\n               loss.backward()\n               optimizer.step()\n            running_loss += loss.item()\n            running_corrects += torch.sum(pred == y.data)\n        \n            if batch%100 == 0 and phase =='training_set':\n                print('Batch:{},Train Loss:{:.4f},Train ACC:{:.4f}'.format(batch,running_loss/batch,100*running_corrects/(16*batch)))\n    \n        epoch_loss = running_loss*16/len(image_datasets[phase])\n        epoch_acc = 100 * running_corrects/len(image_datasets[phase])\n        print('{} Loss:{:.4f} Acc:{:.4f}%'.format(phase,epoch_loss,epoch_acc))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 迁移学习Resnet50","metadata":{}},{"cell_type":"code","source":"from torchvision import models\nresnet50_transfer = models.resnet50(pretrained=True)\n#print(resnet50_transfer)\n\nfor param in resnet50_transfer.parameters():\n    param.requires_grad = False\n\n\nresnet50_transfer.fc = torch.nn.Sequential(\n                            torch.nn.Linear(2048,2048),\n                            torch.nn.ReLU(),\n                            torch.nn.Dropout(p=0.5),\n                            torch.nn.Linear(2048,2048),\n                            torch.nn.ReLU(),\n                            torch.nn.Dropout(p=0.5),\n                            torch.nn.Linear(2048,2)\n)\nprint('=============================================================================================')\nprint(resnet50_transfer)\nprint('=============================================================================================')\n\ncost = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet50_transfer.fc.parameters(),lr=1e-5)\n\nif torch.cuda.is_available(): \n    resnet50_transfer = resnet50_transfer.cuda() \n    cost = cost.cuda()\n\nepoch_n = 10\n\nfor epoch in range(epoch_n):\n    print('Epoch {}/{}'.format(epoch,epoch_n-1))\n    print('-'*20)\n    for phase in ['training_set','test_set']:\n        if phase == 'training_set':\n            print('Training...')\n            vggnet.train(True)\n        else:\n            print('Validing...')\n            vggnet.train(False)\n        running_loss = 0.0\n        running_corrects= 0\n    \n        for batch,data in enumerate(dataloader[phase],1):\n            x,y = data\n            x,y = x.cuda(),y.cuda()\n            y_pred = resnet50_transfer(x)\n            _,pred = torch.max(y_pred.data,1)\n            optimizer.zero_grad()\n            loss = cost(y_pred,y)\n        \n            if phase == 'training_set':\n               loss.backward()\n               optimizer.step()\n            running_loss += loss.item()\n            running_corrects += torch.sum(pred == y.data)\n        \n            if batch%100 == 0 and phase =='training_set':\n                print('Batch:{},Train Loss:{:.4f},Train ACC:{:.4f}'.format(batch,running_loss/batch,100*running_corrects/(16*batch)))\n    \n        epoch_loss = running_loss*16/len(image_datasets[phase])\n        epoch_acc = 100 * running_corrects/len(image_datasets[phase])\n        print('{} Loss:{:.4f} Acc:{:.4f}%'.format(phase,epoch_loss,epoch_acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 模型融合（比赛中常用）","metadata":{}},{"cell_type":"code","source":"#我们在使用单一模型处理某个问题时，很容易遇到泛化瓶颈，模型的泛化能力因一些客观因素受到了限制。\n#为了避免过于庞大耗时的融合模型，我们一般挑选一些结构表较简单，网络层次比较少的神经网络参与到多模型融合中，如果还想继续借用深层次网络来实现多模型融合就需要使用迁移学习方法来辅助模型的融合，以减少模型训练耗\n\n# 模型融合分为过程融合和结果融合，本章仅讨论结果融合\n# 结果融合有三种主要类型：多数表决，直接平均，加权平均\n# 参与融合的各个模型在输出结果上表现得差异性越高，最终得到的融合模型的预测效果越好。\n#对于原始数据比较少的问题，我们可以使用迁移学习进行有效的解决。\n#我们通过对一个训练好的模型进行细微调整，就能将其应用到相似的问题中。\nimport torch\nimport torchvision\nfrom torchvision import datasets,transforms\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n\n#数据预处理\n#torchvision.ImageFolder是一个通用的数据集加载器，他要求我们以data/train/cat这种方式来存放图片，label会顺序返回的\n#我们得到的dataset,它的结构就是[(img_data,class_id),(img_data,class_id),…] \n#注意torchvision.datasets.ImageFolder的使用格式鸭\n\n\ndata_dir = '../input/dogs-vs-cats/dataset'\ndata_transform = {x:transforms.Compose([transforms.Scale([64,64]),transforms.ToTensor()]) for x in ['training_set','test_set']}\nimage_datasets = {x:datasets.ImageFolder(root = os.path.join(data_dir,x),transform = data_transform[x]) for x in ['training_set','test_set']}\ndataloader = {x:torch.utils.data.DataLoader(dataset = image_datasets[x],batch_size=16,shuffle=True) for x in ['training_set','test_set']}\n#拼接文件名：   os.path.join\n#目录下的文件名 os.path.dirname\n#文件是否存在   os.path.exists\n#是否是目录名   os.path.isdir\n#是否是文件名   os.path.isfil\nx_example,y_example = next(iter(dataloader['training_set']))\n\n#展示标签及对应的label\n#index_classes = image_datasets['training_set'].class_to_idx\n#print(index_classes)\n\nimg = torchvision.utils.make_grid(x_example)\nimg = img.numpy().transpose([1,2,0])\n#print([example_classes[i] for i in y_example])\nplt.imshow(img)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\nvgg16 = models.vgg16(pretrained=True)\nresnet50 = models.resnet50(pretrained=True)\n\nfor param in vgg16.parameters():\n    param.requires_grad = False\nvgg16.classifier = torch.nn.Sequential(\n                              torch.nn.Linear(25088,4096),\n                              torch.nn.ReLU(),\n                              torch.nn.Dropout(p=0.5),\n                              torch.nn.Linear(4096,4096),\n                              torch.nn.ReLU(),\n                              torch.nn.Dropout(p=0.5),\n                              torch.nn.Linear(4096,2)\n\n)\n\nfor param in resnet50.parameters():\n    param.requires_grad = False\nresnet50.fc = torch.nn.Sequential(\n                          torch.nn.Linear(2048,2048),\n                            torch.nn.ReLU(),\n                            torch.nn.Dropout(p=0.5),\n                            torch.nn.Linear(2048,2048),\n                            torch.nn.ReLU(),\n                            torch.nn.Dropout(p=0.5),\n                            torch.nn.Linear(2048,2)\n)\n\n\nvgg16 = vgg16.cuda()\nresnet50 = resnet50.cuda()\n\nloss_f_vgg16 = torch.nn.CrossEntropyLoss().cuda()\nloss_f_resnet50 = torch.nn.CrossEntropyLoss().cuda()\nloss_f_vgg16,loss_f_resnet50 = loss_f_vgg16.cuda(),loss_f_resnet50.cuda()\noptimizer_vgg16 = torch.optim.Adam(vgg16.classifier.parameters(), lr=1e-5)\noptimizer_resnet50 = torch.optim.Adam(resnet50.fc.parameters(), lr=1e-5)\n\nweight_vgg16 = 0.6\nweight_resnet50 = 0.4\n\nepoch_n = 10\n\nfor epoch in range(epoch_n):\n    for phase in ['training_set','test_set']:\n        if phase == 'training_set':\n            print('Training...')\n            vgg16.train(True)\n            resnet50.train(True)\n        else:\n            print('Validing...')\n            vgg16.train(False)\n            resnet50.train(False)\n        running_loss_vgg16 = 0.0\n        running_corrects_vgg16 = 0\n        running_loss_resnet50 = 0.0\n        running_corrects_resnet50 = 0\n        blending_running_corrects = 0\n        \n        for batch,data in enumerate(dataloader[phase],1):\n            x,y = data\n            x,y = x.cuda(),y.cuda()\n            y_pred_vgg16 = vgg16(x)\n            y_pred_resnet50 = resnet50(x)\n            blending_y_pred =  y_pred_vgg16*weight_vgg16 + y_pred_resnet50*weight_resnet50\n        \n            _,pred_vgg16 = torch.max(y_pred_vgg16.data,1)\n            _,pred_resnet50 = torch.max(y_pred_resnet50.data,1)\n            _,blending_pred = torch.max(blending_y_pred.data,1)\n        \n            optimizer_vgg16.zero_grad()\n            optimizer_resnet50.zero_grad()\n        \n            loss_vgg16 = loss_f_vgg16( y_pred_vgg16,y)\n            loss_resnet50 = loss_f_resnet50(y_pred_resnet50,y)\n        \n            if phase == 'training_set':\n                loss_vgg16.backward()\n                loss_resnet50.backward()\n                optimizer_vgg16.step()\n                optimizer_resnet50.step()\n            \n            running_loss_vgg16 += loss_vgg16.item()\n            running_corrects_vgg16 += torch.sum(pred_vgg16 == y.data) \n\n            running_loss_resnet50 += loss_resnet50.item()\n            running_corrects_resnet50 += torch.sum(pred_resnet50 == y.data)\n        \n            blending_running_corrects += torch.sum(blending_pred == y.data)\n        \n            if batch % 100 == 0 and phase == 'training_set':\n                print('Batch:{}--vgg16_loss:{:.4f},vgg16_acc:{:.4f}--resnet50_loss:{:.4f},resnet50_acc:{:.4f}--blending_acc:{:.4f}'.format(batch,running_loss_vgg16/batch,100*running_corrects_vgg16/(16*batch),running_loss_resnet50/batch,100*running_corrects_resnet50/(16*batch),100*blending_running_corrects/(16*batch)))\n        epoch_loss_vgg16 = running_loss_vgg16 * 16 / len(image_datasets[phase])\n        epoch_acc_vgg16 = 100 * running_corrects_vgg16 / len(image_datasets[phase])\n        epoch_loss_resnet50 = running_loss_resnet50 * 16/ len(image_datasets[phase])\n        epoch_acc_resnet50 = 100 * running_corrects_resnet50 / len(image_datasets[phase])\n        epoch_blending_acc = 100 * blending_running_corrects / len(image_datasets[phase])\n        \n        print('Epoch BLENDING ACC :{:.4f}'.format(epoch_blending_acc))\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RNN(Recurrent Neural Network)","metadata":{}},{"cell_type":"code","source":"import torchvision\nimport torch\nfrom torchvision import datasets,transforms\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ntransform = transforms.Compose(  [transforms.ToTensor(),transforms.Normalize(mean=[0.5],std=[0.5])] )\ndataset_train = datasets.MNIST(root='./data',transform = transform,train=True,download=True)\ndataset_test  = datasets.MNIST(root='./data',transform = transform,train=False)\n\ntrain_load = torch.utils.data.DataLoader(dataset=dataset_train,batch_size=64,shuffle=True)\ntest_load  = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=64,shuffle=True)\n\nimages,label = next(iter(train_load))\n\nimages_example = torchvision.utils.make_grid(images)\nimages_example = images_example.numpy().transpose(1,2,0) #因为在plt.imshow在现实的时候输入的是(imagesize,imagesize,channels）imshow中，参数img的格式为（channels,imagesize,imagesize）,\n\nmean = [0.5,0.5,0.5]\nstd = [0.5,0.5,0.5]\nimages_example = images_example*std + mean\n\nplt.imshow(images_example)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-02T07:37:23.315143Z","iopub.execute_input":"2021-10-02T07:37:23.315674Z","iopub.status.idle":"2021-10-02T07:37:23.584388Z","shell.execute_reply.started":"2021-10-02T07:37:23.315634Z","shell.execute_reply":"2021-10-02T07:37:23.583685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 循环神经网络主要用于处理序列(Sequences)问题，当然RNN也可以解决分类问题\n#CNN的input维度，output维度，模型结构层次都是固定的。\n#由于在RNN中可以随意控制输入数据及输出数据的数量，具有非常大的灵活性。\nimport torch\n\nclass RNN(torch.nn.Module):\n    def __init__(self):\n        super(RNN,self).__init__()\n        self.rnn = torch.nn.RNN(input_size=28,hidden_size=128,num_layers=1,batch_first=True)\n        self.output = torch.nn.Linear(128,10)\n    \n    def forward(self,input):\n        output,_ = self.rnn(input,None)\n        output = self.output(output[:,-1,:])\n        return output\n#RNN中输入层到输出层默认的维度是(seq,batch,feature)即(序列长度，批次数量，输入或输出特征数)\n\nmodel = RNN()\nprint('===================================================')\nprint(model)\nprint('===================================================')\n\nmodel = model.cuda()\n\noptimizer = torch.optim.Adam(model.parameters())\nloss_f = torch.nn.CrossEntropyLoss()\nloss_f = loss_f.cuda()\n\nepoch_n = 10\n\nfor epoch in range(epoch_n):\n    running_loss = 0.0\n    running_correct = 0\n    testing_correct = 0\n    print('---------------------------------------------------')\n    print('Epoch:{}/{}'.format(epoch,epoch_n))\n    \n    for data in train_load:\n        x_train,y_train = data\n        x_train = x_train.view(-1,28,28)\n        x_train,y_train = x_train.cuda(),y_train.cuda()\n        \n        y_pred = model(x_train)\n        loss = loss_f(y_pred,y_train)\n        _,pred = torch.max(y_pred.data,1)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        running_correct += torch.sum(pred==y_train.data)\n    for data in test_load:\n        x_test,y_test = data\n        x_test = x_test.view(-1,28,28)\n        x_test,y_test = x_test.cuda(),y_test.cuda()\n        outputs = model(x_test)\n        _,pred = torch.max(outputs.data,1)\n        testing_correct += torch.sum(pred == y_test.data)\n    print('Loss:{:.4f} Acc:{:.4f}%---test Acc:{:.4f}'.format(running_loss/len(dataset_train),100*running_correct/len(dataset_train),100*testing_correct/len(dataset_test)))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-02T07:54:59.895441Z","iopub.execute_input":"2021-10-02T07:54:59.895971Z","iopub.status.idle":"2021-10-02T07:57:22.048644Z","shell.execute_reply.started":"2021-10-02T07:54:59.895934Z","shell.execute_reply":"2021-10-02T07:57:22.047893Z"},"trusted":true},"execution_count":null,"outputs":[]}]}