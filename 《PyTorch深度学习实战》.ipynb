{"cells":[{"cell_type":"markdown","metadata":{},"source":["caffe2发布后，将pytorch迁移到caffe2是一个静态图框架，能在手机中运行模型\n","ONNX：开放式可交换神经网络\n","\n","虽然所有深度学习框架都建立在自动微分和计算图的基础上，但有两种截然不同的实现方法:静态图和动态图\n","\n","静态图:在数据实际拿上去进行计算时，先生成计算图实例(Tensoflow使用内部引擎构建优化的计算图)"]},{"cell_type":"markdown","metadata":{},"source":["## 使用静态图 tensorflow.compat.v1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow.compat.v1 as tf\n","tf.compat.v1.disable_eager_execution()\n","\n","lr = 0.001\n","x = tf.placeholder(tf.float32,shape=[None,2],name='x-input')\n","y = tf.placeholder(tf.float32,shape=[None,2],name='y-input')\n","w1 = tf.Variable(tf.random_uniform([2,5],-1,-1),name='w1') #XOR运算\n","w2 = tf.Variable(tf.random_uniform([5,2],-1,-1),name='w2') #XOR运算\n","b1 = tf.Variable(tf.zeros([5]),name='b1')\n","b2 = tf.Variable(tf.zeros([2]),name='b2')\n","a2 = tf.sigmoid(tf.matmul(x,w1)+b1)\n","hyp = tf.matmul(a2,w2) + b2\n","cost = tf.reduce_mean(tf.losses.mean_squared_error(y,hyp))\n","train_step = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n","prediction = tf.argmax(tf.nn.softmax(hyp),1)\n","#一旦解释器完成了读取图定义，我们就可以开始循环访问数据了\n","#接下来启用一个tensorflow对话，这是可以与实现生成的图交互的唯一方式\n","'''\n","with tf.Session() as sess:\n","    sess.run(init) #使用session.run的方法将数据传递到图\n","    for i in range(epoch):\n","        sess.run(train_step,feed_dict={x_:XOR_X,y_:XOR_Y})\n","'''"]},{"cell_type":"markdown","metadata":{},"source":["## 使用动态图 torch\n","    动态功能是命令式图的构建风格，动态图架构不会在传送数据之前生成图，程序在每次迭代数据后都会生成一个新的图实例，并在反向过程完成后将其销毁。\n","    但是你无法根据假设对图进行预优化"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#自动编码器是一种特殊的编码器-解码器网络，属于无监督学习范畴，自动编码器尝试从未标记的数据中进行学习。如果能够训练出一个这样的网路，-就会找到一个好的压缩算法\n","#其可以将高维量变为低维向量存储\n","#语义分割就用到了编码器"]},{"cell_type":"markdown","metadata":{},"source":["torch的基本数据对象是tensor对象:\n","\n","| 数据类型 | CPU张量 | GPU张量\n","| -- | -- | --\n","| 32位浮点型 | torch.FloatTensor | torch.cuda.FloatTensor\n","| 64位浮点型 | torch.DoubleTensor | torch.cuda.DoubleTensor\n","| 8位整型(无符号) | torch.ByteTensor | torch.cuda.ByteTensor\n","| 8位整型(有符号) | torch.CharTensor | torch.cuda.CharTensor\n","| 16位整型(有符号) | torch.ShortTensor | torch.cuda.ShortTensor\n","| 32位整型(有符号) | torch.IntTensor | torch.cuda.IntTensor\n","| 64位整型(有符号) | torch.LongTensor | torch.cuda.LongTensor\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","a = torch.cuda.FloatTensor([1,1,1]) #size,shape,storage都可以查看数据格式\n","#PyTorch遵循为同一操作使用后缀下划线的惯例，但这会发生in-place\n","# a.add(b) 不会对a,b做任何操作\n","# a.add_(b) 会更新a\n","b  = torch.cuda.FloatTensor([1,1,1])\n","\n","x = torch.rand(2,3)\n","xx_0 = torch.cat((x,x))\n","xx_1 = torch.cat((x,x),dim=1)\n","xx_squeeze ="]},{"cell_type":"markdown","metadata":{},"source":["# 一个简单的神经网络"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#PyTorch提供了很好的数据预处理封装器\n","import torch\n","inputs = torch.FloatTensor([2])\n","weights = torch.rand(1,requires_grad=True)\n","bias = torch.rand(1,requires_grad=True)\n","t = inputs @ weights\n","out = t + bias\n","out.backward()\n","weights.grad \n","'''\n",".grad存储任意节点在任意时间点的梯度\n",".data用于访问包含数据的裸张量对象\n","在创建张量时，可以指定该张量是否需要梯度\n","输入的required_grad=False\n","权重和偏差的required_bias=True\n","'''\n","'''\n","张量实例和Function是在图中相互连接的，他们一起构成了非循环计算图\n","除了用户明确定义的张量以外，每个张量都与一个函数相连\n","\n","当我们在遍历数据时，实际是在构件图，并在到达最后一个节点时进行反向传播\n","我们用 lr* .grad 来更新 .data\n","'''\n","'''\n","在每次反向传播之后，我们都要清空梯度\n","每一个张量都有 .data .grad .grad_fn 三个属性，我们通过grad_fn来链接张量\n","'''\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","![title](https://pic2.zhimg.com/80/v2-0a938a33a77b14171cb17f2bbafc0ba1_720w.jpg)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#pytorch通过torch.nn模块提供了高阶API\n","import torch.nn as nn\n","class FizBuzNet(nn.Module):\n","    \"\"\"\n","    2 layer network for predicting fiz or buz\n","    param: input_size -> int\n","    param: output_size -> int\n","    \"\"\"\n","    def __init__(self,input_size,hidden_size,output_size):\n","        super(FizeBuzNet,self).__init__()\n","        self.hidden = nn.Linear(input_size,output_size)\n","        self.out = nn.Linear(hidden_size,output_size)\n","    def forward(self,batch):\n","        hidden = self.hidden(batch)\n","        activated = torch.sigmoid(hidden)\n","        out = self.out(activated)\n","        return out\n","# 我们已经定义了FizBuzNet结构，并将其封装在从torch.nn.Module继承的Python类中\n","# nn.Module实现了两个主要功能 __call__和backward()  用户需要自己写forward和__init__()\n","# 一旦返回网络层的初始化对象，就可以通过调用model对象本身将输入数据传递给模型"]},{"cell_type":"markdown","metadata":{},"source":["- apply() 此函数可以帮助我们将自定义的函数应用于模型的所有参数，它通常用于自定义权重的初始化.\n","\n","- cuda()和cpu():\n","model.cpu()将所有参数转化成CPU张量\n","net = FizBuzNet(input_size,hidden_size,output_size)\n","net.cuda()\n","\n","- train()和eval():\n","这些函数告诉pytorch，模型正在训练模式或者评估模式下运行\n","\n","- parameters():\n","调用parameters会返回模型的所有参数\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#有一种十分重要的方法叫序列容器，它提供了一种更简单的API来构建模型对象，如果模型是连续且直接的，则无需用户编写代码来实现类结构\n","import torch.nn as nn\n","\n","i = 10\n","h = 5\n","o = 1\n","net = nn.Sequential(\n","    nn.Linear(i,h),\n","    nn.Sigmoid(),\n","    nn.Linear(h,o),\n","    nn.Sigmoid()\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# nn.functional 模块\n","nn.functional模块具有将网络节点连接在一起的操作\n","functional模块具有更多功能\n","\n","functional模块也有网络层，但是他比nn提供的网络层抽象性要低，而比我们构建新手模型的方式的抽象性要高"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","a = torch.Tensor([[1,1]])\n","w1 = torch.Tensor([[2,2]])\n","F.linear(a,w1) == a.matmul(w1.t())"]},{"cell_type":"markdown","metadata":{},"source":["# 深度学习工作流\n","\n","- 工作流中的部署测试是人们最挣扎的地方，尤其是应用程序的规模相当大时，如前所述，虽然PyTorch是作为一个面向研究框架构建的，但社群成功的将caffe2集成到了Pytorch后端\n","- 在第八章中，我们通过使用ONNX，PyTorch JIT等的示例来全面讨论模型交付生产的相关内容\n","\n","- DataLoader接收从torch.utils.data.Dataset继承的dataset类，并进行复杂的操作，比如：小批次处理、多线程、随机打乱\n","  num_workers决定该操作多少个并行线程来获取数据，这决定了CPU能否跟得上GPU的速度\n","## 我们需要的三种数据：预训练模型、预处理过的数据集、处理数据的实用函数"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#构建数据处理流程也是一项有难度的任务，在进行一步处理之前，需要将数据转换为浮点数或整数，并进行归一化等等\n","'''\n","PyTorch通过提供抽象类来编写自定义数据集和数据加载器\n","Pytorch中的dataset类是一个高级抽象，它可以处理数据加载其所需要的几乎所有内容\n","用户自定义的dataset类需要覆盖父类的__len__函数和__getitem__函数\n","使用__len__获取数据长度 使用__getitem__来获取数据(输入是索引，输出是数据)\n","'''\n","from dataclasses import dataclass #通过使用动态代码帮助消除__init__中的样板代码\n","from torch.utils.data import Dataset,DataLoader\n","\n","@dataclass(eq=False)\n","class FizBuzDataset(Dataset):\n","    input_size: int \n","    start: int = 0\n","    end: int = 1000\n","    def encoder(self,num):\n","        ret = [int(i) for i in '{0:b}'.format(num)]\n","        return[0] * (self.input_size-len(ret)) + ret\n","    \n","    def __getitem__(self,idx):\n","        x = self.encoder(idx)\n","        if idx % 15 == 0:\n","            y = [1,0,0,0]\n","        elif idx % 5 == 0:\n","            y = [0,1,0,0]\n","        elif idx % 3 == 0:\n","            y = [0,0,0,1]\n","        return x,y\n","    def __len__(self):\n","        return self.end - self.start\n","#数据由程序生成，数据生成的实现位于__getitem__函数中\n","\n","dataset = FizBuzDataset()\n","for i in range(len(dataset)):\n","    x,y = dataset[i]\n","\n","dataloader = Dataloader(dataset,batch_size=10,shuffle=True,num_workers=True)\n","for batch in dataloader:\n","    print(batch)\n","        "]},{"cell_type":"markdown","metadata":{},"source":["### torchvision、torchtext、torchaudio\n","#### torchvision具有强大的API，由(1)数据集，(2)预训练模型，(3)预构建的转换脚本 组成\n","常用的数据集：\n","\n","| 数据集 | 描述\n","| -- | --\n","| MNIST | 70000个 28 * 28 * 1的手写数字\n","| KMNIST | 排列形式类似MNIST的平假名字符数据集\n","| COCO | 大规模的用于目标检测、分割和字幕数据集\n","| LSUN | 大规模场景理解数据集，和COCO类似\n","| Imagenet12 | 2012年图像识别挑战 1400万张图片\n","| CIFAR | 60000张32 * 32 * 3的图片"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torchvision as tv\n","import torch\n","import matplotlib.pyplot as plt\n","\n","\n","#mnist = tv.datasets.MNIST('.',download=True)\n","#plt.imshow(mnist[0][0])\n","\n","#torchvision使用Pillow作为加载图像的默认后端，torchvison提供的所有数据都继承了torch.utils.data.Dataset类,因此每个数据都实现了__len__和__getitem__\n","#这两个神奇的函使所有数据都与Dataloader兼容\n"]},{"cell_type":"markdown","metadata":{},"source":["#  将本地的图像数据封装成 Dataset 进一步传给 DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torchvision\n","import torch\n","import matplotlib.pyplot as plt\n","\n","#images = tv.datasets.ImageFolder('../input/chinese-mnist/data')\n","'''\n","root/dog/xxx.png\n","root/dog/xxy.png\n","root/dog/xxz.png\n","root/cat/123.png\n","root/cat/nsdf3.png\n","root/cat/asd932_.png\n","'''\n","plt.imshow(images[0][0])"]},{"cell_type":"markdown","metadata":{},"source":["# 使用预训练模型"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["resnet18 = torchvision.models.resnet18(pretrained=True)\n","#把参数冻结\n","for param in resnet18.layer1.parameters():\n","    param.requires_grad = False"]},{"cell_type":"markdown","metadata":{},"source":["# 预处理模块"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torchvision.transforms as transforms\n","\n","mean = 0\n","std = 1\n","transform = transforms.Compose(\n","[\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean,std)\n","]\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# 模型实现\n","- 在本节中，我们将讨论pytorch包本身提供的分析和瓶颈工具以及pytorch推荐的训练实用程序ignite\n","- 当模型开始表现不佳时，ignite(训练模块)是一个很好的帮助工具"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["'''\n","with torch.autograd.profiler.profile() as prof:\n","    hyp = resnet18(x)\n","print(prof)\n","print(prof.key_averages())\n","print(prof.tabel('cpu_time'))\n","prof.export_chrome_trace('chrometrace')\n","'''"]},{"cell_type":"markdown","metadata":{},"source":["#### pytorch社群创建了两个工具：torchnet 和 ignite，这里只关注ignite\n","\n","ignite是一种神经网络训练工具，ignite的核心是Engine模块\n","\n","- (1) 它基于默认/自定义训练器或评估器运行模型\n","- (2) 它可以处理程序和评价指标，并对其进行操作\n","- (3) 它可以触发和执行回调\n","\n","#### ignite开辟了一种特殊的方式，通过事件或者触发器与循环进行交互\n","它通过修饰器来触发，以下事件是触发事件:\n","- EPOCH_STARTED\n","- EPOCH_COMPLETED\n","- STARTED\n","- COMPLATED\n","- ITERATION_STARTED\n","- ITERATION_COMPLETED\n","- EXCEPTION_RAISED"]},{"cell_type":"markdown","metadata":{},"source":["# CNN\n","构建完整的CNN需要四种类型的操作:\n","- 卷积层\n","- 非线性层\n","- 池化层\n","- 全连接层\n","![title](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fjeit.ie.ac.cn%2FfileDZYXXXB_ONLY%2Fjournal%2Farticle%2Fdzyxxxb%2Fnewcreate%2F201029-3_mini.jpg&refer=http%3A%2F%2Fjeit.ie.ac.cn&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1642772571&t=321f41a71dd7947b92c43d17e22ad4d7)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#   下载数据 + 转换数据 封装到get_data函数下\n","import torchvision\n","import torch\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","\n","\n","def get_data():\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5),(0.5,0.5,0.5))]\n","    )\n","    \n","    trainset = torchvision.datasets.CIFAR10(root='.',train=True,download=True,transform=transform)\n","    trainloader = torch.utils.data.DataLoader(trainset,batch_size=1,shuffle=True,num_workers=2)\n","    \n","    testset = torchvision.datasets.CIFAR10(root='.',train=False,download=True,transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset,batch_size=1,shuffle=False,num_workers=2)\n","    \n","    return trainloader,testloader\n","   \n","get_data()   "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","# 模型定义\n","class simple_cnn(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3,6,5)\n","        self.pool = nn.MaxPool2d(2)\n","        self.conv2 = nn.Conv2d(6,16,5)\n","        self.fc1 = nn.Linear(16*5*5,120)\n","        self.fc2 = nn.Linear(120,84)\n","        self.fc3 = nn.Linear(84,10)\n","    def forward(self,x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1,16*5*5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","net = simple_cnn()\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n","train_loader,test_loader = get_data()\n","\n","\n","MAX_EPOCH = 10\n","train_curve = list()\n","valid_curve = list()\n","log_interval = 50\n","\n","for epoch in range(MAX_EPOCH): \n","    loss_mean = 0.\n","    correct = 0.\n","    total = 0.\n","    net.train()\n","    for i, data in enumerate(train_loader):\n","        # forward\n","        inputs, labels = data\n","        outputs = net(inputs)\n","        # backward\n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        # update weights\n","        optimizer.step()\n","        # 统计分类情况\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).squeeze().sum().numpy()\n","        # 打印训练信息\n","        loss_mean += loss.item()\n","        train_curve.append(loss.item())\n","        if (i+1) % log_interval == 0:\n","            loss_mean = loss_mean / log_interval\n","            print(\"Training:Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n","                epoch, MAX_EPOCH, i+1, len(train_loader), loss_mean, correct / total))\n","            loss_mean = 0.\n"," \n"]},{"cell_type":"markdown","metadata":{},"source":["# 语义分割\n","\n","- 我们将CamVid数据集用于LinkNet的实现\n","- Linknet是由编码器+解码器组成的，LinkNet论文的作者将resnet18作为编码器\n","\n","### 我们主要使用了五个组件来构建linknet\n","- ConvBlock 卷积 + 非线性\n","- DeconvBlock 反卷积 + 非线性\n","- nn.MaxPool2d 池化\n","- EncoderBlock\n","- DecoderBlock"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self,inp,out,kernal,stride,pad,bias,act):\n","        super().__init()\n","        if act:\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(inp,out,kernal,stride,pad,bias=bias),\n","                nn.BatchNorm2d(num_features=out),\n","                nn.ReLU()\n","            )\n","        else:\n","            self.conv_block = nn.Sequential(\n","                nn.Conv2d(inp,out,kernal,stride,pad,bias=bias),\n","                nn.BatchNorm2d(num_features=out),\n","            )\n","    def forward(self,x):\n","        return seld.conv_block(x)\n","    \n","\n","class DeconvBlock(nn.Module):\n","    def __init__(self,inp,out,kernal,stride,pad):\n","        super().__init__()\n","        self.conv_transpose = nn.nn.ConvTranspose2d(inp,out,kernal,stride,pad)\n","        self.batchnorm = nn.BatchNorm2d(out)\n","        self.relu = nn.ReLU()\n","    def forward(self,x,output_size):#outputsize是期望输出的维度\n","        convt_out = self.conv_transpose(x,output_size=output_size)\n","        batchnormout = self.batchnorm(convt_out)\n","        return self.relu(batchnormout)\n","\n","class EncoderBlock(nn.Module):\n","    'Resnet18'\n","    def __init__(self,inp,out):\n","        super().__init__()\n","        self.block1 = nn.Sequential(\n","            ConvBlock(inp=inp,out=out,kernal=3,stride=2,pad=1,bias=True,act=True),\n","            ConvBlock(inp=out,out=out,kernal=3,stride=1,pad=1,bias=True,act=True)\n","        )\n","        \n","        self.block2 = nn.Sequential(\n","            ConvBlock(inp=out,out=out,kernal=3,stride=1,pad=1,bias=True,act=True),\n","            ConvBlock(inp=out,out=out,kernal=3,stride=2,pad=1,bias=True,act=True)\n","        )\n","        \n","        self.residue = ConvBlock(inp=out,out=out,kernal=3,stride=2,pad=1,bias=True,act=True)\n","    \n","    def forward(self,x):\n","        out1 = self.block1(x)\n","        residue = self.residue(x)\n","        out2 = self.block2(out1+residue)\n","        return out1 + out2\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self,inp,out):\n","        super().__init__()\n","        self.conv1 = ConvBlock(inp=inp,out=inp//4,kernel=1,stride=1,pad=0,bias=True,act=True)\n","        self.deconv = DeconvBlock(inp=inp//4,out=inp//4,kernel=3,stride=2,pad=1)\n","        self.conv2 = ConvBlock(inp=inp,out=out,kernel=1,stride=1,pad=0,bias=True,act=True)\n","    def forward(self,x,output_size):\n","        conv1 = self.conv1(x)\n","        deconv = self.deconv(conv1,output_size=output_size)\n","        conv2 = self.conv2(deconv)\n","        return conv2\n","\n","class SegmentationModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.init_conv = Convblock(inp=3,out=64,kernel=7,stride=2,pad=3,bias=True,act=True)\n","        self.init_maxpool = nn.MaxPool2d(kernel_szie=3,stride=2,padding=1)\n","        \n","        self.encoder1 = EncoderBlock(inp=64,out=64)\n","        self.encoder2 = EncoderBlock(inp=64,out=128)\n","        self.encoder3 = EncoderBlock(inp=128,out=256)\n","        self.encoder4 = EncoderBlock(inp=256,out=512)\n","        \n","        self.decoder4 = DecoderBlock(inp=512,out=256)\n","        self.decoder3 = DecoderBlock(inp=256,out=128)\n","        self.decoder2 = DecoderBlock(inp=128,out=64)\n","        self.decoder1 = DecoderBlock(inp=64,out=64)\n","        \n","        self.final_deconv1 = DeconvBlock(inp=64,out=64)\n","        self.final_conv = ConvBlock(inp=32,out=32,kernal=3,stride=1,pad=1,bias=True,act=True)\n","        self.final_deconv2 = DeconvBlock(inp=32,out=2,kernal=2,stride=2,pad=0)\n","    def forward(self,x):\n","        init_conv = self.init_conv(x)\n","        e1 = self.encoder1(init_maxpool)\n","        e2 = self.encoder2(e1)\n","        e3 = self.encoder2(e2)\n","        e4 = self.encoder2(e3)\n","        \n","        d4 = self.decoder4(e4,e3.size()) + e3\n","        d3 = self.decoder4(e4,e3.size()) + e2\n","        d2 = self.decoder4(e4,e3.size()) + e1\n","        d1 = self.decoder1(d2,init_maxpool.size())\n","        \n","        final_deconv1 = self.final_deconv1(d1,init_conv.size())\n","        final_conv = self.final_conv(final_deconv1)\n","        final_deconv2 = self.final_deconv2(final_conv,x.size())\n","        \n","        return final_deconv2"]},{"cell_type":"markdown","metadata":{},"source":["# 使用预训练模型进行语义分割\n","!wget nv url -O path"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!wget -nv http://news.neuq.edu.cn/__local/A/9E/25/208374FD430A5995C27861117FB_D510CA86_3B5BC.jpg -O bird.png\n","img = Image.open('./bird.png')\n","img = img.crop((80,0,450,250))\n","img.save('./bird.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install matplotlib==2.2.3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#!wget -nv https://img-blog.csdnimg.cn/20200212171003937.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM2NzkxNTk=,size_16,color_FFFFFF,t_70 -O bird.png\n","from torchvision import models\n","#fcn = models.segmentation.fcn_resnet101(pretrained=True).eval()\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision.transforms as T\n","import numpy as np\n","\n","def decode_segmap(image, nc=21):\n","   \n","  label_colors = np.array([(0, 0, 0),  # 0=background\n","               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n","               (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\n","               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n","               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n","               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n","               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n","               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n","               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n"," \n","  r = np.zeros_like(image).astype(np.uint8)\n","  g = np.zeros_like(image).astype(np.uint8)\n","  b = np.zeros_like(image).astype(np.uint8)\n","   \n","  for l in range(0, nc):\n","    idx = image == l\n","    r[idx] = label_colors[l, 0]\n","    g[idx] = label_colors[l, 1]\n","    b[idx] = label_colors[l, 2] \n","  rgb = np.stack([r, g, b], axis=2)\n","  return rgb\n","\n","def segment(net, path):\n","  img = Image.open(path)\n","  plt.imshow(img); plt.axis('off'); plt.show()\n","  # Comment the Resize and CenterCrop for better inference results\n","  trf = T.Compose([T.Resize(256), \n","                   T.CenterCrop(224), \n","                   T.ToTensor(), \n","                   T.Normalize(mean = [0.485, 0.456, 0.406], \n","                               std = [0.229, 0.224, 0.225])])\n","  inp = trf(img).unsqueeze(0)  \n","  out = net(inp)['out']\n","  om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n","  rgb = decode_segmap(om)\n","  plt.imshow(rgb); plt.axis('off'); plt.show()\n","\n","segment(fcn,'./bird.png')"]},{"cell_type":"markdown","metadata":{},"source":["# 序列数据处理\n","- 人类的语言异常复杂，所有词汇的组合超过宇宙中原子的数量，但是深度神经网络通过诸如词嵌入和注意力之类的技术可以很好的处理此问题\n","- LSTM和GRU(门控循环单元)是最常见的两种RNN\n","- 下一个重要的发明是Attention,它可以帮助网络专注于输入的重要部分，而不是通过搜索整个输入来找到答案\n","- 词嵌入是一种革命性思想，它通过比较单词在单词簇中的分布来挖掘单词的概念意义\n","\n","循环神经网络痛过引入状态变量存储过去的信息和当前的输入，从而可以确定当前的输出"]},{"cell_type":"markdown","metadata":{},"source":["### 自回归模型 : 输入是定的 x(t-T) ~ x(t)\n","### 隐自回归模型 : 对于过去观测的总结(隐状态) + 当前输入 "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#使用SNLI（stanford natural lauguage inference）作为数据集\n","#%matplotlib inline\n","#!pip install d2l\n","import torch\n","from torch import nn\n","import matplotlib.pyplot as plt\n","from d2l import torch as d2l\n","\n","T = 1000\n","time = torch.arange(1,T+1,dtype=torch.float32)\n","x = torch.sin(0.01*time) + torch.normal(0,0.2,(T,))\n","#plt.plot(time,x)\n","#plt.grid()\n","\n","\n","#将这个序列转换为 特征-标签 对，[x(t-T),...,x(t-1)] 输出y(t)\n","tau = 4\n","features = torch.zeros((T-tau,tau))\n","for i in range(tau):\n","    features[:,i] = x[i:T-tau+i]\n","labels = x[tau:].reshape((-1,1))\n","batch_size,n_train = 16,600\n","train_iter = d2l.load_array((features[:n_train], labels[:n_train]),batch_size, is_train=True)\n","\n","#使用·一个·非常简单的架构训练模型：一个拥有两个全连接层的多层感知机，ReLU激活函数和平方损失\n","'''\n","nn.init.xavier_uniform_(m.weight)\n","net = nn.sequential(...)\n","net.apply(init_weights)\n","'''\n","def init_weights(m):\n","    if type(m) == nn.Linear:\n","        nn.init.xavier_uniform_(m.weight)\n","        \n","def get_net():\n","    net = nn.Sequential(nn.Linear(4,10),\n","                        nn.ReLU(),\n","                        nn.Linear(10,1))\n","    net.apply(init_weights)\n","    return net\n","loss = nn.MSELoss(reduction='none')\n","\n","def train(net,train_iter,loss,epochs,lr):\n","    trainer = torch.optim.Adam(net.parameters(),lr)\n","    for epoch in range(epochs):\n","        for X,y in train_iter:\n","            trainer.zero_grad()\n","            l = loss(net(X),y)\n","            l.sum().backward()\n","            trainer.step()\n","        print('epoch:'+str(epoch + 1) + '  |  '+'loss:'+str(d2l.evaluate_loss(net, train_iter, loss)))\n","net = get_net()\n","train(net,train_iter,loss,5,0.01)\n","\n","\n","#预测\n","onestep_preds = net(features)\n","d2l.plot([time, time[tau:]],\n","         [x.detach().numpy(), onestep_preds.detach().numpy()], 'time',\n","         'x', legend=['data', '1-step preds'], xlim=[1, 1000],\n","         figsize=(6, 3))\n"]},{"cell_type":"markdown","metadata":{},"source":["## 文本预处理\n","- 1,将文本作为字符串加载到内存中\n","- 2,将字符串拆分成词元\n","- 3，建立一个词表，将拆分的词映射到数字索引\n","- 4，将文本转换为数字索引序列，方便微型操作"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#!pip install d2l\n","#!pip install matplotlib==2.2.3\n","import collections\n","import re\n","from d2l import torch as d2l\n","'''\n","我们从H.G.Well的时光机器中加载文本，只有30000多个单词，足够我们小试牛刀\n","'''\n","d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt','090b5e7e70c295757f55df93cb0a180b9691891a')\n","\n","def read_time_machine():\n","    with open(d2l.download('time_machine'),'r') as f:\n","        lines = f.readlines()\n","    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n","\n","lines = read_time_machine()\n","print(f'# 文本总行数: {len(lines)}')\n","print(lines[0])\n","print(lines[10])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["'''\n","tokenize函数将文本行列表(lines)作为输入，列表中的每个元素都是一个文本序列。每个文本序列又被拆分成一个词元列表\n","词元(token)是文本的基本单位\n","'''\n","def tokenize(lines,token='word'):\n","    if token=='word':\n","        return [line.split() for line in lines]\n","    elif token == 'char':\n","        return [list[line] for line in lines]\n","    else:\n","        print('未知词元类型:' + token)\n","\n","tokens = tokenize(lines)\n","for i in range(11):\n","    print(tokens[i])\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Vocab:  #@save\n","    \"\"\"文本词表\"\"\"\n","    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n","        if tokens is None:\n","            tokens = []\n","        if reserved_tokens is None:\n","            reserved_tokens = []\n","        # 按出现频率排序\n","        counter = count_corpus(tokens)\n","        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n","                                   reverse=True)\n","        # 未知词元的索引为0\n","        self.idx_to_token = ['<unk>'] + reserved_tokens\n","        self.token_to_idx = {token: idx\n","                             for idx, token in enumerate(self.idx_to_token)}\n","        self.idx_to_token, self.token_to_idx = [], dict()\n","        for token, freq in self._token_freqs:\n","            if freq < min_freq:\n","                break\n","            if token not in self.token_to_idx:\n","                self.idx_to_token.append(token)\n","                self.token_to_idx[token] = len(self.idx_to_token) - 1\n","\n","    def __len__(self):\n","        return len(self.idx_to_token)\n","\n","    def __getitem__(self, tokens):\n","        if not isinstance(tokens, (list, tuple)):\n","            return self.token_to_idx.get(tokens, self.unk)\n","        return [self.__getitem__(token) for token in tokens]\n","\n","    def to_tokens(self, indices):\n","        if not isinstance(indices, (list, tuple)):\n","            return self.idx_to_token[indices]\n","        return [self.idx_to_token[index] for index in indices]\n","\n","    @property\n","    def unk(self):  # 未知词元的索引为0\n","        return 0\n","\n","    @property\n","    def token_freqs(self):\n","        return self._token_freqs\n","\n","def count_corpus(tokens):  #@save\n","    \"\"\"统计词元的频率\"\"\"\n","    # 这里的tokens是1D列表或2D列表\n","    if len(tokens) == 0 or isinstance(tokens[0], list):\n","        # 将词元列表展平成一个列表\n","        tokens = [token for line in tokens for token in line]\n","    return collections.Counter(tokens)"]},{"cell_type":"markdown","metadata":{},"source":["#### 在静态图计算中，序列长度必须是给定的，这就是基于静态图的框架与基于NLP任务不兼容的原因，但是Tensorflow提供了名为dynamic_rnn的API来处理此类问题"]},{"cell_type":"markdown","metadata":{},"source":["# 生成网络\n","生成网络已经在不同的深度学习领域，尤其在计算机视觉领域展现出喜人的成果，一些或活跃的领域包括:去模糊，提高图像分辨率，为图像填充缺失片段，音频去噪，文本生成语音，自动回复消息，文本生成图像\n","### 1.自回归模型\n","### 2.GAN\n","![title](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Foscimg.oschina.net%2Foscnet%2Fc1a9d388-5b87-48db-9dd7-a4cd39f6f354.png&refer=http%3A%2F%2Foscimg.oschina.net&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1642853488&t=45af02ccca6a1cc21326fd9e5182d648)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torchvision.transforms as transforms\n","import torchvision\n","import torch\n","\n","def get_data():\n","    transform = transforms.Compose(\n","        [transforms.ToTensor()]\n","    )\n","    \n","    trainset = torchvision.datasets.MNIST(root='.',train=True,download=True,transform=transform)\n","    trainloader = torch.utils.data.DataLoader(trainset,batch_size=1,shuffle=True,num_workers=0)\n","    \n","    testset = torchvision.datasets.MNIST(root='.',train=False,download=True,transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset,batch_size=1,shuffle=False,num_workers=0)\n","    \n","    return trainloader,testloader\n","\n","train_loader,test_loader = get_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#这里只写GAN了嗷\n","import torch.nn as nn\n","import torch\n","import torchvision\n","import torch.optim as optim\n","\n","\n","class DiscriminatorNet(nn.Module):\n","    \"\"\"\n","    A three hidden layer Discriminator\n","    输入是图片784，输出是真假（0，1）\n","    \"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        n_features = 784#28*28\n","        n_out = 1\n","        \n","        self.hidden = nn.Sequential(\n","                nn.Linear(n_features,1024),\n","                nn.LeakyReLU(0.2),\n","                nn.Dropout(0.3),\n","                nn.Linear(1024,512),\n","                nn.LeakyReLU(0.2),\n","                nn.Dropout(0.3),\n","                nn.Linear(512,256),          \n","                nn.LeakyReLU(0.2),\n","                nn.Dropout(0.3),\n","                nn.Linear(256,n_out),\n","                nn.Sigmoid()\n","        )\n","    def forward(self,x):\n","        x = self.hidden(x)\n","        return x\n","\n","\n","def train_discriminator(optimizer,real_data,fake_data):\n","    optimizer.zero_grad()\n","    #1,Train on Real Data\n","    prediction_real = discriminator(real_data)\n","    error_real = loss(prediction_real,real_data_target(real_data.size(0)))#zhegesize就是\n","    error_real.backward()\n","    \n","    #2,Train on Fake Data\n","    prediction_fake = discriminator(fake_data)\n","    error_fake = loss(prediction_fake,fake_data_target(real_data.size(0)))\n","    error_fake.backward()\n","    \n","    #3,update weight with gradients\n","    optimizer.step()\n","    #return error\n","    return error_real + error_fake,prediction_real,prediction_fake\n","\n","        \n","\n","def real_data_target(size):\n","    data = torch.ones(size,1)\n","    if torch.cuda.is_available():return data.cuda()\n","    return data\n","def fake_data_target(size):\n","    data = torch.zeros(size,1)\n","    if torch.cuda.is_available():return data.cuda()\n","    return data\n","def noise(size):\n","    n = torch.randn(size,100)\n","    if torch.cuda.is_available():return n.cuda()\n","    return n\n","\n","class GeneratorNet(nn.Module):\n","    \"\"\"\n","    A three hidden layer Generator\n","    输入是100，输出是784\n","    \"\"\"\n","    def __init__(self):\n","        super().__init__()\n","        n_features = 100#28*28\n","        n_out = 784\n","        \n","        self.hidden = nn.Sequential(\n","                nn.Linear(n_features,256),\n","                nn.LeakyReLU(0.2),\n","                nn.Linear(256,512),\n","                nn.LeakyReLU(0.2),\n","                nn.Linear(512,1024),          \n","                nn.LeakyReLU(0.2),\n","                nn.Linear(1024,n_out),\n","                nn.Tanh()\n","        )\n","    def forward(self,x):\n","        x = self.hidden(x)\n","        return x\n","\n","def train_generator(optimizer,real_data,fake_data):\n","    \n","    optimizer.zero_grad()\n","    picture_fake = generator(fake_data)\n","    picture_real = real_data\n","    \n","    error = loss_g(picture_fake,picture_real)\n","    error.backward()\n","\n","    #3,update weight with gradients\n","    optimizer.step()\n","    #return error\n","    return error,picture_real,picture_fake\n","    \n","    \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#主函数\n","discriminator = DiscriminatorNet()\n","generator = GeneratorNet()\n","d_optimizer = optim.Adam(discriminator.parameters(),lr=0.0002)\n","g_optimizer = optim.Adam(generator.parameters(),lr=0.0002)\n","loss = nn.BCELoss()\n","loss_g = nn.MSELoss()\n","\n","discriminator.train()\n","generator.train()\n","\n","EPOCH_NUM = 500\n","\n","for epoch in range(EPOCH_NUM):\n","    for i, data in enumerate(train_loader):\n","        \n","        real_data, _ = data\n","        real_data = real_data[0][0]\n","        real_data = real_data.view(1,784)\n","\n","        fake_data1 = noise(1)\n","        fake_data2 = generator(fake_data1)\n","        \n","        e_d,_,_ = train_discriminator(d_optimizer,real_data,fake_data2)\n","        e_g,_,_ = train_generator(g_optimizer,real_data,fake_data1)\n","    print('loss of D:'+str(e_d)+'  loss of G:'+str(e_g))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x = noise(1)\n","img = generator(x).detach().numpy()\n","img.resize(28,28)\n","plt.imshow(img)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Cycle Gan\n","![title](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fmedia.paperweekly.site%2FLUOHAO_1513259995.6203003.png%3FimageView2%2F2%2Fw%2F800%2Fq%2F70%7Cimageslim&refer=http%3A%2F%2Fmedia.paperweekly.site&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1643168659&t=aaf695141fffe0abe04a634abedf0836)"]},{"cell_type":"markdown","metadata":{},"source":["# 强化学习"]},{"cell_type":"markdown","metadata":{},"source":["- 在整个强化学习范式中，我们只关心如何从交互中学习，决策者被认为是一个智能体\n","- 智能体必须观察周围的环境并根据环境做出决策或采取行动\n","- 在环境中实施某个决策得到的响应被称为奖励\n","- 智能体的目标是在其生命周期内最大化其累积的回报\n","- 我们必须平衡两个因素，探索和开发 探索是随机性因子，开发是最优决策\n","- 我们将使用OpenAI的Gym库\n","- 有明确的结束点的任务成为回合制任务（目标就是回合结束时累计奖励最大）\n","- 有些任务可能会永远进行下去，这种任务被称为持续任务\n","\n","### 区分奖励和回报（未来奖励的总和称为回报）\n","显然，近期回报可能相对更重要一些，我们引入了折扣回报的概念： Goal = Max(R(t+1),gamma*R(t+2),gamma^2*R(t+2)......)\n","一个好的做法是让 gamma=0.9，他会一直固定，直到试验结束\n","\n","### 马尔可夫决策过程(MDP)\n","五个因素： 有限状态，有限行动，有限奖励，折扣率，环境的一步动态\n","- 花些时间模拟所有行动和状态，来更好地了解他们，通过详细罗列智能体可以处于的所有状态以及在所有状态下可以执行的所有行动和每个行动的概率，我们可以模拟环境，明确所有环境后，环境的一步动态就定了\n","- 函数V是用来评估某个状态的价值的\n","- 函数Q是用来预测每个行动的预期回报的\n","- 假设V和Q任一个都是可以训练的神经网络\n","-贝尔曼方程指出，在每个时间点的回报等于下一个时间步的估计奖励加上之后状态的折扣奖励"]},{"cell_type":"markdown","metadata":{},"source":["# 将pytorch应用到生产\n","- onnx(开放神经网络交换)的缺点：onnx的脚本模式，onnx运行一次图来获取有关图的信息，然后将其转为onnx格式，因此，onnx无法迁移模型中的控制流\n","- 将pytorch用于生产的第二种方法是在pytorch中构建高性能后端\n","- torchscript将python模型转化为序列化格式，该格式可以加载到高性能空间，torchscript可以被pytorch的后端libtorch读取，\n","\n","### 本章介绍\n","- (1) 使用Flask为标准的Pytorch模型提供服务\n","- (2) 将Pytorch转换为Mxnet，并使用Mxnet提供服务\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# pth转onnx 把之前的语义分割模型转成了onnx格式\n","inp = [[[[0]*224]*224]*3]\n","inp[0][0][0][0] = 1\n","dummy_input = torch.Tensor(inp)\n","torch.onnx.export(fcn,dummy_input,'./segment.onnx',verbose=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#当你觉得模型服务器(诸如clipper,tensorrt)不好用时，可以试试MXNet的模型服务器"]},{"cell_type":"markdown","metadata":{},"source":["ONNX 是使用跟踪来创建优化的中间表示，也就是说，他通过模型传递一个虚拟输入，当模型被执行时\n","他记录pytorch的操作，并将这操作转化为中间表示。\n","\n","与ONNX一样，torchscript可以作为中间结果保存在磁盘中\n","\n","## 但是，保存的Torchscript模型可以在没有python依赖项的环境中部署加载\n","- torchscript允许两种方式来生成这种中间表示：\n","- (1)和ONNX一样，跟踪+记录\n","- (2)torch.jit.script"]},{"cell_type":"markdown","metadata":{},"source":["# RedisAI"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
